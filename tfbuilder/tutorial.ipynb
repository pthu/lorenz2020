{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tfbuilder tutorial\n",
    "The whole machinery of tfbuilder can be used by importing the convert function from the tfbuilder library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfbuilder import convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arguments `convert()`\n",
    "    input_path      = folder path in which the files to be converted reside\n",
    "    output_path     = folder path to which all tf-modules are to be written\n",
    "    tlg_out         = `True` if one wants TLG codes as folder names `False` if folder names from metadata\n",
    "    ignore_empty    = `True` if source files that don't produce slot numbers need to be ignored\n",
    "    generic         = Generic metadata to be present in every tf-file to be produced\n",
    "    lang            = language (referring to languages available in `langsettings`)\n",
    "    typ             = subtype of a language, if special behavious is required, like `tlge` (tlg-e cdrom)\n",
    "    header          = if True, the convertor expects csv-files to have a header\n",
    "    version         = version number to be assigned to the tf-module\n",
    "    langsettings    = langsettings to be imported; usually, this is the langsettings provided by tfbuilder\n",
    "    multiprocessing = False --> no multiprocessing\n",
    "                    = True  --> active multiprocessing; authomatic assignment of number of processor threads\n",
    "                    = int   --> manual assingment of number of processor threads\n",
    "    chunksize       = number of files to be assigned to each thread each cycle\n",
    "    inspect         = return useful information about tags and attributes of XML input to inspect the source\n",
    "    silent          = if True, all TF-messages are suppressed\n",
    "    \n",
    "    \n",
    "#### remarks `generic` and `langsettings`:\n",
    "Both are accessible and changeable in tf_config.py. However, one is able to pass his/her own settings (=dictionary) to the convert function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert('~/github/pthu/lorenz2020/tfbuilder/test/english', \n",
    "        '~/github/pthu/lorenz2020/tfbuilder/test/english/out',\n",
    "        ignore_empty=False,\n",
    "        tlg_out=False,\n",
    "        lang='generic', \n",
    "        typ=False, \n",
    "        header=False,\n",
    "        multiprocessing=False,\n",
    "        chunksize=1,\n",
    "        silent=False,\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert csv file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation Homer (James Tauber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "PATH = os.path.expanduser('~/github/pthu/lorenz2020/tfbuilder/test')\n",
    "\n",
    "csvfile = open(PATH + '/greek_csv/tlg0012-001.csv', 'w+')\n",
    "\n",
    "with open(os.path.expanduser(PATH + '/greek_csv/tlg0012-001.txt'), 'r') as james:\n",
    "    for line in james.readlines():\n",
    "        ref, text = line.split(' ', 1)\n",
    "        ref1, ref2 = ref.split('.')\n",
    "        csvfile.write(f'{ref1}\\t{ref2}\\t{text}')\n",
    "\n",
    "csvfile.close()\n",
    "\n",
    "with open(PATH + '/greek_csv/tlg0012-001.csv', 'r') as ernst:\n",
    "    pprint(ernst.readlines()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert('~/github/pthu/lorenz2020/tfbuilder/test/greek_csv', \n",
    "        '~/github/pthu/lorenz2020/tfbuilder/test/greek_csv/out',\n",
    "        ignore_empty=False,\n",
    "        tlg_out=False,\n",
    "        lang='greek', \n",
    "        typ='tlge', \n",
    "        header=False,\n",
    "        multiprocessing=False,\n",
    "        chunksize=1,\n",
    "        silent=False,\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `generic` in `tf_config`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_metadata_modified = {\n",
    "    'convertor_execution': 'Donald Duck',             # Please replace this by your own name!\n",
    "    'convertor_author': 'Willie Wortel',              # Idem!\n",
    "    'convertor_date': 'February, 1816',               # Replace by appropriate date\n",
    "    'convertor_institution': 'The Duck University',   # Replace by your own institution/company\n",
    "    'famous_uncle': 'Dagobert Duck',\n",
    "    \n",
    "    # DO NOT CHANGE!\n",
    "    'convertor_version': '1.0.0',           # NO CHANGE!\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `langsettings` in `tf_config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpertools import langtools\n",
    "from collections import OrderedDict\n",
    "\n",
    "langsettings_modified = {\n",
    "    'english': {\n",
    "        #OUTPUT DIR STRUCTURE\n",
    "        #Output dir struct; NB these variable names need to be defined in the metadata!\n",
    "        #Multiple items in the list define multiple options that will be checked from left to right\n",
    "        #Output author/title/editor (or one of the other options if they are not provided\n",
    "        'dir_struct': [['author', 'editor'], \n",
    "                       ['title', 'book', 'work'], \n",
    "                       ['editor']],\n",
    "        \n",
    "        #TF variables!\n",
    "        'slot_type': 'word',\n",
    "        'intFeatures': set(),\n",
    "        'nonIntFeatures': {'otype', 'oslots', 'otext'},\n",
    "        'struct_counter': OrderedDict([('_sentence', 1), ('_phrase', 1)]),\n",
    "        'struct_counter_metadata': {\n",
    "            '_sentence': f\"sentences defined by the following delimiters: {{{'.', '?', '!',}}}\",\n",
    "            '_phrase': f\"sentences defined by the following delimiters: {{{',', ';', ':',}}}\",\n",
    "        },\n",
    "        'generic': {}, # = Metadata used by TF\n",
    "        \n",
    "        #LANGUAGE VARIABLES\n",
    "        #Unicode norm\n",
    "        'udnorm': 'NFD',\n",
    "        #Package of langtools\n",
    "        'langtool': langtools.Generic,\n",
    "        'replace_func': langtools.Generic.replace,\n",
    "        #Tokenizer\n",
    "        'tokenizer': langtools.Generic.splitTokenize,\n",
    "        'tokenizer_args': {'punc': True, \n",
    "                           'clean': False,\n",
    "                           'splitters': None,\n",
    "                           'non_splitters': (\"-\", \"'\"),},\n",
    "        'token_out': OrderedDict([('pre', {'text': False, 'description': 'interpunction before word'}),\n",
    "                                 ('orig', {'text': True, 'description': 'the original format of the word without interpunction'}),\n",
    "                                 ('post', {'text': False, 'description': 'interpunction after word'}),\n",
    "                                 ]),\n",
    "        #Lemmatizer\n",
    "        'lemmatizer': None,\n",
    "        #Text formats\n",
    "        'text_formats': {'orig': {'otext_name': 'fmt:text-orig-full',\n",
    "                                  'format': '{pre}{orig}{post}',\n",
    "                                  'function': langtools.Generic.origWord,\n",
    "                                  'description': 'original format of the word including punctuation'},\n",
    "                         'main': {'otext_name': 'fmt:text-orig-main',\n",
    "                                  'format': '{main} ',\n",
    "                                  'function': langtools.Generic.mainWord,\n",
    "                                  'description': 'normalized format of the word excluding punctuation'},\n",
    "                         'plain': {'otext_name': 'fmt:text-orig-plain',\n",
    "                                   'format': '{plain} ',\n",
    "                                   'function': langtools.Generic.plainWord,\n",
    "                                   'description': 'plain format in lowercase'},\n",
    "                        },\n",
    "\n",
    "        #XML VARIABLES\n",
    "        #Define the fields from xml metadata that need to be preserved\n",
    "        # concat = True means that subfields are concatenated\n",
    "        # concat = False means that subfields get their own metadata entry\n",
    "        'xmlmetadata': {'titleStmt': {'concat': False, 'delimit': ', ', 'end': ''},\n",
    "                     'publicationStmt': {'concat': True, 'delimit': ', ', 'end': '.'},\n",
    "                     'sourceDesc': {'concat': True, 'delimit': ', ', 'end': '.'},\n",
    "                     'license': {'concat': True, 'delimit': ', ', 'end': '.'},\n",
    "                     'availability': {'concat': True, 'delimit': ', ', 'end': '.'},\n",
    "                    },\n",
    "        \n",
    "        #Define the tag in which sectioning can be found\n",
    "        'section_tags': {'div',},\n",
    "        #Define in which key the section name can be found\n",
    "        'section_keys': {'subtype'},\n",
    "        #Define attribute keys that are superfluous and need to be ignored\n",
    "        'ignore_attrib_keys': set(),\n",
    "        #Define attribute keys that do not contain a section name\n",
    "        'non_section_keys': set(),\n",
    "        #Define values that are no sections, although they are in the right key\n",
    "        'non_section_values': set(),\n",
    "        ##Define attribute values that are superfluous and need to be ignored\n",
    "        ##'ignore_attrib_values': set(),\n",
    "        #Define tags that contain text elements that need not to be processed as regular text but as features\n",
    "        'non_text_tags': set(),\n",
    "        #Define attributes that have values that are feature names (values will be calculated automatically)\n",
    "        'feature_attribs': {'corresp', 'source'},\n",
    "        #Define sentence delimiters to be counted by struct_counter\n",
    "        'sentence_delimit': {'.', '?', '!',},\n",
    "        #Define phrase delimiters to be counted by struct_counter\n",
    "        'phrase_delimit': {',', ';', ':',},\n",
    "    },\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert('~/github/pthu/lorenz2020/tfbuilder/test/english', \n",
    "        '~/github/pthu/lorenz2020/tfbuilder/test/english/out',\n",
    "        generic=generic_metadata_modified,\n",
    "        langsettings=langsettings_modified,\n",
    "        ignore_empty=False,\n",
    "        tlg_out=False,\n",
    "        lang='english', \n",
    "        typ=False, \n",
    "        header=False,\n",
    "        multiprocessing=False,\n",
    "        chunksize=1,\n",
    "        silent=False,\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
